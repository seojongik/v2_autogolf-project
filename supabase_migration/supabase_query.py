#!/usr/bin/env python3
"""
Supabase Query Tool - MCP ëŒ€ìš© ë§ŒëŠ¥ DB ì¡°íšŒ ë„êµ¬
ê°œë°œ ì‹œ í•„ìš”í•œ ëª¨ë“  DB ì •ë³´ë¥¼ ì¡°íšŒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

=== ê¸°ë³¸ ì‚¬ìš©ë²• ===

    # í…Œì´ë¸” ëª©ë¡ (í–‰ ìˆ˜ í¬í•¨)
    python supabase_query.py --list-tables

    # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ (ì»¬ëŸ¼, íƒ€ì…, ì œì•½ì¡°ê±´)
    python supabase_query.py --schema v2_staff_manager

    # ë°ì´í„° ì¡°íšŒ
    python supabase_query.py -t v2_staff_manager -l 5

=== ê³ ê¸‰ ìŠ¤í‚¤ë§ˆ ì •ë³´ ===

    # ê¸°ë³¸í‚¤, ì™¸ë˜í‚¤, ì¸ë±ìŠ¤ ì „ì²´ ë³´ê¸°
    python supabase_query.py --full-schema v2_staff_manager

    # ì™¸ë˜í‚¤ ê´€ê³„ë§Œ ë³´ê¸°
    python supabase_query.py --fk v2_staff_manager

    # ì¸ë±ìŠ¤ ë³´ê¸°
    python supabase_query.py --indexes v2_staff_manager

    # ì œì•½ì¡°ê±´ ë³´ê¸°
    python supabase_query.py --constraints v2_staff_manager

    # í…Œì´ë¸” ê°„ ê´€ê³„ë„ (ERD í…ìŠ¤íŠ¸)
    python supabase_query.py --relations v2_staff_manager

    # ëª¨ë“  í…Œì´ë¸” ê´€ê³„ ìš”ì•½
    python supabase_query.py --all-relations

=== ë°ì´í„° ë¶„ì„ ===

    # ì»¬ëŸ¼ë³„ ë°ì´í„° ìƒ˜í”Œ ë° í†µê³„
    python supabase_query.py --analyze v2_staff_manager

    # íŠ¹ì • ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ëª©ë¡
    python supabase_query.py --distinct v2_staff_manager.staff_status

    # ì»¬ëŸ¼ë³„ NULL ë¹„ìœ¨
    python supabase_query.py --null-check v2_staff_manager

=== ë°ì´í„° ì¡°íšŒ ===

    # ê¸°ë³¸ ì¡°íšŒ
    python supabase_query.py -t v2_staff_manager

    # ì¡°ê±´ ê²€ìƒ‰
    python supabase_query.py -t v2_staff_manager -w "branch_id=test"

    # ë³µí•© ì¡°ê±´
    python supabase_query.py -t v2_staff_manager -w "branch_id=test" -w "staff_status=ì¬ì§"

    # LIKE ê²€ìƒ‰
    python supabase_query.py -t v2_staff_manager --like "manager_name=%í˜œ%"

    # ì •ë ¬
    python supabase_query.py -t v2_staff_manager -o "updated_at DESC" -l 5

    # íŠ¹ì • í•„ë“œë§Œ
    python supabase_query.py -t v2_staff_manager -f manager_id,manager_name

    # JSON ì¶œë ¥
    python supabase_query.py -t v2_staff_manager -l 3 --json

=== SQL ì§ì ‘ ì‹¤í–‰ ===

    python supabase_query.py --sql "SELECT COUNT(*) FROM v2_staff_manager"

=== CUD ì‘ì—… ===

    # INSERT
    python supabase_query.py -t v2_test --insert '{"name": "test"}'

    # UPDATE (where í•„ìˆ˜)
    python supabase_query.py -t v2_test --update '{"value": 456}' -w "name=test"

    # DELETE (where í•„ìˆ˜)
    python supabase_query.py -t v2_test --delete -w "name=test"
"""

import json
import argparse
import sys
from pathlib import Path
from datetime import datetime, date
from decimal import Decimal

try:
    import psycopg2
    from psycopg2.extras import RealDictCursor
except ImportError:
    print("psycopg2 íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì„¤ì¹˜: pip install psycopg2-binary")
    sys.exit(1)

# í‚¤ íŒŒì¼ ê²½ë¡œ
KEYS_FILE = Path(__file__).parent / "supabase_keys.json"


def load_keys():
    """Supabase í‚¤ íŒŒì¼ ë¡œë“œ"""
    if not KEYS_FILE.exists():
        print(f"âŒ í‚¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {KEYS_FILE}")
        sys.exit(1)

    with open(KEYS_FILE, 'r') as f:
        return json.load(f)


def get_connection():
    """Supabase PostgreSQL ì—°ê²°"""
    keys = load_keys()
    conn_string = keys.get('connection_string')

    try:
        conn = psycopg2.connect(conn_string)
        return conn
    except Exception as e:
        print(f"âŒ DB ì—°ê²° ì‹¤íŒ¨: {e}")
        sys.exit(1)


def json_serial(obj):
    """JSON ì§ë ¬í™” í—¬í¼"""
    if isinstance(obj, (datetime, date)):
        return obj.isoformat()
    if isinstance(obj, Decimal):
        return float(obj)
    raise TypeError(f"Type {type(obj)} not serializable")


# ============================================
# í…Œì´ë¸” ëª©ë¡ ë° ê¸°ë³¸ ì •ë³´
# ============================================

def list_tables(conn, verbose=False):
    """ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ë° í–‰ ìˆ˜ ì¡°íšŒ"""
    query = """
        SELECT
            t.table_name,
            pg_stat_user_tables.n_live_tup as row_count,
            pg_size_pretty(pg_total_relation_size(quote_ident(t.table_name))) as size
        FROM information_schema.tables t
        LEFT JOIN pg_stat_user_tables ON t.table_name = pg_stat_user_tables.relname
        WHERE t.table_schema = 'public' AND t.table_type = 'BASE TABLE'
        ORDER BY t.table_name
    """
    with conn.cursor() as cur:
        cur.execute(query)
        tables = cur.fetchall()

    print(f"\nğŸ“‹ í…Œì´ë¸” ëª©ë¡ ({len(tables)}ê°œ)")
    print("-" * 60)
    print(f"{'í…Œì´ë¸”ëª…':<40} {'í–‰ ìˆ˜':>10} {'í¬ê¸°':>10}")
    print("-" * 60)

    for table_name, row_count, size in tables:
        row_str = str(row_count) if row_count else '?'
        size_str = size if size else '?'
        print(f"{table_name:<40} {row_str:>10} {size_str:>10}")
    print()


def list_views(conn):
    """ë·° ëª©ë¡ ì¡°íšŒ"""
    query = """
        SELECT table_name, view_definition
        FROM information_schema.views
        WHERE table_schema = 'public'
        ORDER BY table_name
    """
    with conn.cursor() as cur:
        cur.execute(query)
        views = cur.fetchall()

    if not views:
        print("\nğŸ“‹ ë·° ì—†ìŒ")
        return

    print(f"\nğŸ“‹ ë·° ëª©ë¡ ({len(views)}ê°œ)")
    print("-" * 60)
    for name, definition in views:
        print(f"\nâ€¢ {name}")
        if definition:
            # ì²« 100ìë§Œ í‘œì‹œ
            short_def = definition[:200] + "..." if len(definition) > 200 else definition
            print(f"  {short_def}")


# ============================================
# ìŠ¤í‚¤ë§ˆ ì •ë³´
# ============================================

def get_schema(conn, table_name):
    """í…Œì´ë¸” ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ ì¡°íšŒ"""
    query = """
        SELECT
            c.column_name,
            c.data_type,
            c.character_maximum_length,
            c.numeric_precision,
            c.is_nullable,
            c.column_default,
            col_description(
                (SELECT oid FROM pg_class WHERE relname = c.table_name),
                c.ordinal_position
            ) as column_comment
        FROM information_schema.columns c
        WHERE c.table_schema = 'public' AND c.table_name = %s
        ORDER BY c.ordinal_position
    """
    with conn.cursor() as cur:
        cur.execute(query, (table_name,))
        columns = cur.fetchall()

    if not columns:
        print(f"âŒ í…Œì´ë¸” '{table_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None

    print(f"\nğŸ“Š í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ: {table_name}")
    print("=" * 90)
    print(f"{'Column':<30} {'Type':<20} {'Null':<6} {'Default':<20} {'Comment'}")
    print("-" * 90)

    for col in columns:
        name, dtype, char_len, num_prec, nullable, default, comment = col

        # íƒ€ì… í¬ë§·íŒ…
        type_str = dtype
        if char_len:
            type_str = f"{dtype}({char_len})"
        elif num_prec:
            type_str = f"{dtype}({num_prec})"

        null_str = "YES" if nullable == 'YES' else "NO"
        default_str = str(default)[:18] + '..' if default and len(str(default)) > 20 else (default or '')
        comment_str = comment or ''

        print(f"{name:<30} {type_str:<20} {null_str:<6} {default_str:<20} {comment_str}")

    print()
    return columns


def get_primary_key(conn, table_name):
    """ê¸°ë³¸í‚¤ ì¡°íšŒ"""
    query = """
        SELECT kcu.column_name
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu
            ON tc.constraint_name = kcu.constraint_name
        WHERE tc.table_schema = 'public'
            AND tc.table_name = %s
            AND tc.constraint_type = 'PRIMARY KEY'
        ORDER BY kcu.ordinal_position
    """
    with conn.cursor() as cur:
        cur.execute(query, (table_name,))
        pks = [row[0] for row in cur.fetchall()]
    return pks


def get_foreign_keys(conn, table_name):
    """ì™¸ë˜í‚¤ ì¡°íšŒ"""
    query = """
        SELECT
            kcu.column_name,
            ccu.table_name AS foreign_table,
            ccu.column_name AS foreign_column,
            tc.constraint_name
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu
            ON tc.constraint_name = kcu.constraint_name
        JOIN information_schema.constraint_column_usage ccu
            ON ccu.constraint_name = tc.constraint_name
        WHERE tc.table_schema = 'public'
            AND tc.table_name = %s
            AND tc.constraint_type = 'FOREIGN KEY'
    """
    with conn.cursor() as cur:
        cur.execute(query, (table_name,))
        fks = cur.fetchall()
    return fks


def get_indexes(conn, table_name):
    """ì¸ë±ìŠ¤ ì¡°íšŒ"""
    query = """
        SELECT
            i.relname as index_name,
            a.attname as column_name,
            ix.indisunique as is_unique,
            ix.indisprimary as is_primary
        FROM pg_class t
        JOIN pg_index ix ON t.oid = ix.indrelid
        JOIN pg_class i ON i.oid = ix.indexrelid
        JOIN pg_attribute a ON a.attrelid = t.oid AND a.attnum = ANY(ix.indkey)
        WHERE t.relname = %s AND t.relkind = 'r'
        ORDER BY i.relname, a.attnum
    """
    with conn.cursor() as cur:
        cur.execute(query, (table_name,))
        indexes = cur.fetchall()
    return indexes


def get_constraints(conn, table_name):
    """ì œì•½ì¡°ê±´ ì¡°íšŒ"""
    query = """
        SELECT
            tc.constraint_name,
            tc.constraint_type,
            kcu.column_name,
            cc.check_clause
        FROM information_schema.table_constraints tc
        LEFT JOIN information_schema.key_column_usage kcu
            ON tc.constraint_name = kcu.constraint_name
        LEFT JOIN information_schema.check_constraints cc
            ON tc.constraint_name = cc.constraint_name
        WHERE tc.table_schema = 'public' AND tc.table_name = %s
        ORDER BY tc.constraint_type, tc.constraint_name
    """
    with conn.cursor() as cur:
        cur.execute(query, (table_name,))
        constraints = cur.fetchall()
    return constraints


def show_full_schema(conn, table_name):
    """ì „ì²´ ìŠ¤í‚¤ë§ˆ ì •ë³´ (ì»¬ëŸ¼ + PK + FK + ì¸ë±ìŠ¤ + ì œì•½ì¡°ê±´)"""
    # ê¸°ë³¸ ìŠ¤í‚¤ë§ˆ
    get_schema(conn, table_name)

    # ê¸°ë³¸í‚¤
    pks = get_primary_key(conn, table_name)
    if pks:
        print(f"ğŸ”‘ ê¸°ë³¸í‚¤: {', '.join(pks)}")

    # ì™¸ë˜í‚¤
    fks = get_foreign_keys(conn, table_name)
    if fks:
        print(f"\nğŸ”— ì™¸ë˜í‚¤:")
        for col, ftable, fcol, cname in fks:
            print(f"   {col} â†’ {ftable}.{fcol}")

    # ì¸ë±ìŠ¤
    indexes = get_indexes(conn, table_name)
    if indexes:
        print(f"\nğŸ“‡ ì¸ë±ìŠ¤:")
        current_idx = None
        for idx_name, col_name, is_unique, is_primary in indexes:
            if is_primary:
                continue  # PKëŠ” ì´ë¯¸ í‘œì‹œí•¨
            if idx_name != current_idx:
                unique_str = " (UNIQUE)" if is_unique else ""
                print(f"   â€¢ {idx_name}{unique_str}: ", end="")
                current_idx = idx_name
            print(f"{col_name} ", end="")
        print()

    # ì œì•½ì¡°ê±´
    constraints = get_constraints(conn, table_name)
    check_constraints = [c for c in constraints if c[1] == 'CHECK']
    unique_constraints = [c for c in constraints if c[1] == 'UNIQUE']

    if unique_constraints:
        print(f"\nâœ“ UNIQUE ì œì•½:")
        for cname, ctype, col, clause in unique_constraints:
            print(f"   â€¢ {col}")

    if check_constraints:
        print(f"\nâœ“ CHECK ì œì•½:")
        for cname, ctype, col, clause in check_constraints:
            if clause:
                print(f"   â€¢ {clause[:60]}...")

    print()


def show_fk_relations(conn, table_name):
    """ì™¸ë˜í‚¤ ê´€ê³„ í‘œì‹œ"""
    # ì´ í…Œì´ë¸”ì´ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”
    fks = get_foreign_keys(conn, table_name)

    # ì´ í…Œì´ë¸”ì„ ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”
    query = """
        SELECT
            tc.table_name as referencing_table,
            kcu.column_name as referencing_column,
            ccu.column_name as referenced_column
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu
            ON tc.constraint_name = kcu.constraint_name
        JOIN information_schema.constraint_column_usage ccu
            ON ccu.constraint_name = tc.constraint_name
        WHERE tc.constraint_type = 'FOREIGN KEY'
            AND ccu.table_name = %s
    """
    with conn.cursor() as cur:
        cur.execute(query, (table_name,))
        refs = cur.fetchall()

    print(f"\nğŸ”— í…Œì´ë¸” ê´€ê³„: {table_name}")
    print("=" * 60)

    if fks:
        print(f"\nâ†’ {table_name}ì´(ê°€) ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”:")
        for col, ftable, fcol, cname in fks:
            print(f"   {table_name}.{col} â†’ {ftable}.{fcol}")

    if refs:
        print(f"\nâ† {table_name}ì„(ë¥¼) ì°¸ì¡°í•˜ëŠ” í…Œì´ë¸”:")
        for reftable, refcol, mycol in refs:
            print(f"   {reftable}.{refcol} â†’ {table_name}.{mycol}")

    if not fks and not refs:
        print("   (ê´€ê³„ ì—†ìŒ)")
    print()


def show_all_relations(conn):
    """ëª¨ë“  í…Œì´ë¸” ê°„ ê´€ê³„"""
    query = """
        SELECT
            tc.table_name as from_table,
            kcu.column_name as from_column,
            ccu.table_name as to_table,
            ccu.column_name as to_column
        FROM information_schema.table_constraints tc
        JOIN information_schema.key_column_usage kcu
            ON tc.constraint_name = kcu.constraint_name
        JOIN information_schema.constraint_column_usage ccu
            ON ccu.constraint_name = tc.constraint_name
        WHERE tc.constraint_type = 'FOREIGN KEY'
            AND tc.table_schema = 'public'
        ORDER BY tc.table_name, ccu.table_name
    """
    with conn.cursor() as cur:
        cur.execute(query)
        relations = cur.fetchall()

    print(f"\nğŸ”— ì „ì²´ í…Œì´ë¸” ê´€ê³„ë„ ({len(relations)}ê°œ)")
    print("=" * 70)

    if not relations:
        print("   (ì™¸ë˜í‚¤ ê´€ê³„ ì—†ìŒ)")
    else:
        for from_t, from_c, to_t, to_c in relations:
            print(f"   {from_t}.{from_c:<30} â†’ {to_t}.{to_c}")
    print()


# ============================================
# ë°ì´í„° ë¶„ì„
# ============================================

def analyze_table(conn, table_name):
    """í…Œì´ë¸” ë°ì´í„° ë¶„ì„ (ì»¬ëŸ¼ë³„ í†µê³„)"""
    # ë¨¼ì € ì»¬ëŸ¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    col_query = """
        SELECT column_name, data_type
        FROM information_schema.columns
        WHERE table_schema = 'public' AND table_name = %s
        ORDER BY ordinal_position
    """
    with conn.cursor() as cur:
        cur.execute(col_query, (table_name,))
        columns = cur.fetchall()

    if not columns:
        print(f"âŒ í…Œì´ë¸” '{table_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # í–‰ ìˆ˜
    with conn.cursor() as cur:
        cur.execute(f"SELECT COUNT(*) FROM {table_name}")
        total_rows = cur.fetchone()[0]

    print(f"\nğŸ“Š í…Œì´ë¸” ë¶„ì„: {table_name}")
    print(f"   ì´ í–‰ ìˆ˜: {total_rows:,}")
    print("=" * 80)

    for col_name, col_type in columns:
        print(f"\nâ–¸ {col_name} ({col_type})")

        with conn.cursor() as cur:
            # NULL ê°œìˆ˜
            cur.execute(f"SELECT COUNT(*) FROM {table_name} WHERE {col_name} IS NULL")
            null_count = cur.fetchone()[0]
            null_pct = (null_count / total_rows * 100) if total_rows > 0 else 0

            # DISTINCT ê°œìˆ˜
            cur.execute(f"SELECT COUNT(DISTINCT {col_name}) FROM {table_name}")
            distinct_count = cur.fetchone()[0]

            print(f"   NULL: {null_count:,} ({null_pct:.1f}%) | DISTINCT: {distinct_count:,}")

            # ìˆ«ìí˜•ì´ë©´ min/max/avg
            if col_type in ('integer', 'bigint', 'numeric', 'real', 'double precision'):
                cur.execute(f"SELECT MIN({col_name}), MAX({col_name}), AVG({col_name}) FROM {table_name}")
                min_val, max_val, avg_val = cur.fetchone()
                if min_val is not None:
                    print(f"   MIN: {min_val} | MAX: {max_val} | AVG: {avg_val:.2f if avg_val else 0}")

            # ë¬¸ìí˜•ì´ë©´ ìƒ˜í”Œ ê°’ë“¤
            elif col_type in ('character varying', 'text', 'character'):
                cur.execute(f"""
                    SELECT {col_name}, COUNT(*) as cnt
                    FROM {table_name}
                    WHERE {col_name} IS NOT NULL
                    GROUP BY {col_name}
                    ORDER BY cnt DESC
                    LIMIT 5
                """)
                samples = cur.fetchall()
                if samples:
                    print(f"   TOP ê°’: ", end="")
                    sample_strs = [f"'{v}'({c})" for v, c in samples]
                    print(", ".join(sample_strs))
    print()


def show_distinct_values(conn, table_column):
    """íŠ¹ì • ì»¬ëŸ¼ì˜ ê³ ìœ ê°’ ëª©ë¡"""
    if '.' not in table_column:
        print("âŒ í˜•ì‹: í…Œì´ë¸”ëª….ì»¬ëŸ¼ëª… (ì˜ˆ: v2_staff_manager.staff_status)")
        return

    table_name, col_name = table_column.split('.', 1)

    query = f"""
        SELECT {col_name}, COUNT(*) as cnt
        FROM {table_name}
        GROUP BY {col_name}
        ORDER BY cnt DESC
    """

    try:
        with conn.cursor() as cur:
            cur.execute(query)
            values = cur.fetchall()

        print(f"\nğŸ“‹ ê³ ìœ ê°’: {table_name}.{col_name} ({len(values)}ê°œ)")
        print("-" * 50)

        for val, cnt in values:
            val_str = str(val) if val is not None else '(NULL)'
            print(f"   {val_str:<30} {cnt:>10}")
        print()

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")


def check_nulls(conn, table_name):
    """ì»¬ëŸ¼ë³„ NULL ë¹„ìœ¨ ì²´í¬"""
    col_query = """
        SELECT column_name
        FROM information_schema.columns
        WHERE table_schema = 'public' AND table_name = %s
        ORDER BY ordinal_position
    """
    with conn.cursor() as cur:
        cur.execute(col_query, (table_name,))
        columns = [row[0] for row in cur.fetchall()]

        cur.execute(f"SELECT COUNT(*) FROM {table_name}")
        total = cur.fetchone()[0]

    if not columns:
        print(f"âŒ í…Œì´ë¸” '{table_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\nğŸ“Š NULL ë¹„ìœ¨: {table_name} (ì´ {total:,}í–‰)")
    print("-" * 50)

    for col in columns:
        with conn.cursor() as cur:
            cur.execute(f"SELECT COUNT(*) FROM {table_name} WHERE {col} IS NULL")
            null_count = cur.fetchone()[0]

        pct = (null_count / total * 100) if total > 0 else 0
        bar = "â–ˆ" * int(pct / 5) + "â–‘" * (20 - int(pct / 5))

        if null_count > 0:
            print(f"   {col:<30} {bar} {pct:>5.1f}% ({null_count:,})")
    print()


# ============================================
# ë°ì´í„° ì¡°íšŒ
# ============================================

def select_data(conn, table_name, fields=None, where=None, like=None, order=None, limit=10, as_json=False):
    """ë°ì´í„° ì¡°íšŒ"""
    field_str = ', '.join(fields) if fields else '*'
    query = f"SELECT {field_str} FROM {table_name}"
    params = []

    conditions = []

    # WHERE ì¡°ê±´
    if where:
        for w in where:
            if '=' in w:
                key, value = w.split('=', 1)
                conditions.append(f"{key.strip()} = %s")
                params.append(value.strip())

    # LIKE ì¡°ê±´
    if like:
        if '=' in like:
            key, value = like.split('=', 1)
            conditions.append(f"{key.strip()} LIKE %s")
            params.append(value.strip())

    if conditions:
        query += " WHERE " + " AND ".join(conditions)

    if order:
        query += f" ORDER BY {order}"

    if limit:
        query += f" LIMIT {limit}"

    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(query, params)
            rows = cur.fetchall()

        if as_json:
            print(json.dumps([dict(r) for r in rows], indent=2, ensure_ascii=False, default=json_serial))
            return rows

        print(f"\nğŸ” ì¡°íšŒ ê²°ê³¼: {table_name} ({len(rows)}ê±´)")
        print(f"   Query: {query}")
        if params:
            print(f"   Params: {params}")
        print("-" * 80)

        if not rows:
            print("  (ë°ì´í„° ì—†ìŒ)")
        else:
            for i, row in enumerate(rows):
                print(f"\n[{i+1}]", end=" ")
                # ID ê³„ì—´ ë¨¼ì €
                id_keys = [k for k in row.keys() if 'id' in k.lower()]
                name_keys = [k for k in row.keys() if 'name' in k.lower()]
                priority_keys = id_keys + name_keys

                shown = []
                for key in priority_keys:
                    if key in row:
                        print(f"{key}={row[key]}", end=" | ")
                        shown.append(key)
                print()

                for key, value in row.items():
                    if key not in shown:
                        value_str = str(value)
                        if len(value_str) > 60:
                            value_str = value_str[:60] + "..."
                        print(f"    {key}: {value_str}")

        print()
        return rows

    except Exception as e:
        print(f"âŒ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return None


def execute_sql(conn, sql):
    """ì§ì ‘ SQL ì‹¤í–‰"""
    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(sql)

            if sql.strip().upper().startswith('SELECT'):
                rows = cur.fetchall()
                print(f"\nğŸ” SQL ì‹¤í–‰ ê²°ê³¼ ({len(rows)}ê±´)")
                print(f"   Query: {sql}")
                print("-" * 80)

                for i, row in enumerate(rows):
                    print(f"[{i+1}] {dict(row)}")
                return rows
            else:
                conn.commit()
                print(f"âœ… SQL ì‹¤í–‰ ì„±ê³µ")
                print(f"   ì˜í–¥ë°›ì€ í–‰: {cur.rowcount}ê°œ")
                return True

    except Exception as e:
        conn.rollback()
        print(f"âŒ SQL ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        return None


# ============================================
# CUD ì‘ì—…
# ============================================

def insert_data(conn, table_name, data_json):
    """ë°ì´í„° ì‚½ì…"""
    try:
        data = json.loads(data_json)
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return False

    columns = list(data.keys())
    values = list(data.values())
    placeholders = ', '.join(['%s'] * len(values))

    query = f"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({placeholders}) RETURNING *"

    try:
        with conn.cursor(cursor_factory=RealDictCursor) as cur:
            cur.execute(query, values)
            result = cur.fetchone()
            conn.commit()

        print(f"âœ… INSERT ì„±ê³µ: {table_name}")
        print(f"   ì‚½ì…ëœ ë°ì´í„°: {dict(result)}")
        return True

    except Exception as e:
        conn.rollback()
        print(f"âŒ INSERT ì‹¤íŒ¨: {e}")
        return False


def update_data(conn, table_name, data_json, where):
    """ë°ì´í„° ì—…ë°ì´íŠ¸"""
    if not where:
        print("âŒ UPDATEì—ëŠ” --where ì¡°ê±´ì´ í•„ìš”í•©ë‹ˆë‹¤ (ì•ˆì „ì„ ìœ„í•´)")
        return False

    try:
        data = json.loads(data_json)
    except json.JSONDecodeError as e:
        print(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return False

    set_parts = []
    params = []
    for key, value in data.items():
        set_parts.append(f"{key} = %s")
        params.append(value)

    query = f"UPDATE {table_name} SET {', '.join(set_parts)}"

    conditions = []
    for w in where:
        if '=' in w:
            key, value = w.split('=', 1)
            conditions.append(f"{key.strip()} = %s")
            params.append(value.strip())

    query += " WHERE " + " AND ".join(conditions)

    try:
        with conn.cursor() as cur:
            cur.execute(query, params)
            affected = cur.rowcount
            conn.commit()

        print(f"âœ… UPDATE ì„±ê³µ: {table_name}")
        print(f"   ì˜í–¥ë°›ì€ í–‰: {affected}ê°œ")
        return True

    except Exception as e:
        conn.rollback()
        print(f"âŒ UPDATE ì‹¤íŒ¨: {e}")
        return False


def delete_data(conn, table_name, where):
    """ë°ì´í„° ì‚­ì œ"""
    if not where:
        print("âŒ DELETEì—ëŠ” --where ì¡°ê±´ì´ í•„ìš”í•©ë‹ˆë‹¤ (ì•ˆì „ì„ ìœ„í•´)")
        return False

    query = f"DELETE FROM {table_name}"
    params = []

    conditions = []
    for w in where:
        if '=' in w:
            key, value = w.split('=', 1)
            conditions.append(f"{key.strip()} = %s")
            params.append(value.strip())

    query += " WHERE " + " AND ".join(conditions)

    try:
        with conn.cursor() as cur:
            cur.execute(query, params)
            affected = cur.rowcount
            conn.commit()

        print(f"âœ… DELETE ì„±ê³µ: {table_name}")
        print(f"   ì‚­ì œëœ í–‰: {affected}ê°œ")
        return True

    except Exception as e:
        conn.rollback()
        print(f"âŒ DELETE ì‹¤íŒ¨: {e}")
        return False


# ============================================
# Main
# ============================================

def main():
    parser = argparse.ArgumentParser(
        description='Supabase Query Tool - MCP ëŒ€ìš© ë§ŒëŠ¥ DB ì¡°íšŒ ë„êµ¬',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )

    # ê¸°ë³¸ ì˜µì…˜
    parser.add_argument('--table', '-t', help='í…Œì´ë¸”ëª…')
    parser.add_argument('--fields', '-f', help='ì¡°íšŒí•  í•„ë“œ (ì‰¼í‘œ êµ¬ë¶„)')
    parser.add_argument('--where', '-w', action='append', help='WHERE ì¡°ê±´')
    parser.add_argument('--like', help='LIKE ì¡°ê±´ (ì˜ˆ: name=%%test%%)')
    parser.add_argument('--order', '-o', help='ì •ë ¬ (ì˜ˆ: created_at DESC)')
    parser.add_argument('--limit', '-l', type=int, default=10, help='ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 10)')

    # í…Œì´ë¸”/ìŠ¤í‚¤ë§ˆ ì •ë³´
    parser.add_argument('--list-tables', action='store_true', help='í…Œì´ë¸” ëª©ë¡')
    parser.add_argument('--list-views', action='store_true', help='ë·° ëª©ë¡')
    parser.add_argument('--schema', '-s', help='í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ')
    parser.add_argument('--full-schema', help='ì „ì²´ ìŠ¤í‚¤ë§ˆ (PK, FK, ì¸ë±ìŠ¤ í¬í•¨)')
    parser.add_argument('--fk', help='ì™¸ë˜í‚¤ ê´€ê³„')
    parser.add_argument('--indexes', help='ì¸ë±ìŠ¤ ì¡°íšŒ')
    parser.add_argument('--constraints', help='ì œì•½ì¡°ê±´ ì¡°íšŒ')
    parser.add_argument('--relations', help='í…Œì´ë¸” ê´€ê³„')
    parser.add_argument('--all-relations', action='store_true', help='ì „ì²´ í…Œì´ë¸” ê´€ê³„')

    # ë°ì´í„° ë¶„ì„
    parser.add_argument('--analyze', '-a', help='í…Œì´ë¸” ë°ì´í„° ë¶„ì„')
    parser.add_argument('--distinct', '-d', help='ê³ ìœ ê°’ ëª©ë¡ (í…Œì´ë¸”.ì»¬ëŸ¼)')
    parser.add_argument('--null-check', help='NULL ë¹„ìœ¨ ì²´í¬')

    # SQL
    parser.add_argument('--sql', help='ì§ì ‘ SQL ì‹¤í–‰')

    # CUD
    parser.add_argument('--insert', help='INSERT (JSON)')
    parser.add_argument('--update', help='UPDATE (JSON)')
    parser.add_argument('--delete', action='store_true', help='DELETE')

    # ì¶œë ¥
    parser.add_argument('--json', action='store_true', help='JSON ì¶œë ¥')

    args = parser.parse_args()

    # ì¸ì ì—†ìœ¼ë©´ ë„ì›€ë§
    if len(sys.argv) == 1:
        print(__doc__)
        return

    conn = get_connection()
    print("âœ… Supabase ì—°ê²° ì„±ê³µ")

    try:
        # í…Œì´ë¸”/ë·° ëª©ë¡
        if args.list_tables:
            list_tables(conn)
            return
        if args.list_views:
            list_views(conn)
            return

        # ìŠ¤í‚¤ë§ˆ ì •ë³´
        if args.schema:
            get_schema(conn, args.schema)
            return
        if args.full_schema:
            show_full_schema(conn, args.full_schema)
            return
        if args.fk:
            show_fk_relations(conn, args.fk)
            return
        if args.indexes:
            indexes = get_indexes(conn, args.indexes)
            print(f"\nğŸ“‡ ì¸ë±ìŠ¤: {args.indexes}")
            for idx in indexes:
                print(f"   {idx}")
            return
        if args.constraints:
            constraints = get_constraints(conn, args.constraints)
            print(f"\nâœ“ ì œì•½ì¡°ê±´: {args.constraints}")
            for c in constraints:
                print(f"   {c}")
            return
        if args.relations:
            show_fk_relations(conn, args.relations)
            return
        if args.all_relations:
            show_all_relations(conn)
            return

        # ë°ì´í„° ë¶„ì„
        if args.analyze:
            analyze_table(conn, args.analyze)
            return
        if args.distinct:
            show_distinct_values(conn, args.distinct)
            return
        if args.null_check:
            check_nulls(conn, args.null_check)
            return

        # SQL
        if args.sql:
            execute_sql(conn, args.sql)
            return

        # í…Œì´ë¸” í•„ìš”í•œ ì‘ì—…ë“¤
        if not args.table:
            print("âŒ --table ì˜µì…˜ì´ í•„ìš”í•©ë‹ˆë‹¤. ë„ì›€ë§: python supabase_query.py --help")
            return

        # CUD
        if args.insert:
            insert_data(conn, args.table, args.insert)
            return
        if args.update:
            update_data(conn, args.table, args.update, args.where)
            return
        if args.delete:
            delete_data(conn, args.table, args.where)
            return

        # SELECT
        fields = args.fields.split(',') if args.fields else None
        select_data(conn, args.table, fields, args.where, args.like, args.order, args.limit, args.json)

    finally:
        conn.close()


if __name__ == '__main__':
    main()
